{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0.1,  0.04,  0.6,  0,  0.1])\n",
    "t = np.array([0,    1,     0,    0,    0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.04 0.6  0.   0.1 ]\n",
      "[0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26032"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((y - t)**2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0.1,  0.8,  0.02,  0,  0.1])\n",
    "t = np.array([0,    1,     0,    0,    0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012079999999999997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((y - t)**2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, t):\n",
    "    return (np.sum((y - t)**2))/y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y, t):\n",
    "        return (np.sum(np.abs(y - t)))/y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([0.1,  0.04,  0.6,  0,  0.1])\n",
    "y2 = np.array([0.1,  0.8,  0.02,  0,  0.1])\n",
    "t = np.array([0,    1,     0,    0,    0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26032"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y1, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012079999999999997"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y2, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    return -np.sum(t * np.log(y + 1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2188733248713257"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y1, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22314342631421757"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.8  0.02 0.   0.1 ]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.reshape(1, y.size)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entroy function for mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1b = np.array([ [0.1,  0.04,  0.6,  0,  0.1], [0.1,  0.4,  0.2,  0,  0.1], [0.1,  0.12,  0.1,  0.5,  0.1] ])\n",
    "y2b = np.array([ [0.1,  0.7,  0.12,  0,  0.1], [0.1,  0.8,  0.2,  0,  0.1], [0.1,  0.5,  0.1,  0.123,  0.1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    batch_size = y.shape[0] \n",
    "    return -np.sum(t * np.log(y + 1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0851421698708723"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y1b, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42432173598526096"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y2b, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2188733248713257"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y1, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h))/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(x):\n",
    "    return x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, 4, 0.1)\n",
    "y = fun1(x)\n",
    "plt.plot(x, y)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49999999999994493\n",
      "0.9000000000000674\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(fun1, 0.2))\n",
    "print(numerical_diff(fun1, 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun2_1(x1, x2):\n",
    "    return x1**2 + x2**2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial derivative at x2 = 4\n",
    "def fun2_part1(x1):\n",
    "    return 2*x1 + 2*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial derivative at x1 = 3\n",
    "def fun2_part2(x2):\n",
    "    return 2*3 + 2*x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999999999953388"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(fun2_part1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999999999953388"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(fun2_part2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0001"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 + 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "\n",
    "    grad = np.zeros_like(x) \n",
    "\n",
    "    for idx in range(x.size):\n",
    "        # save x[idx]\n",
    "        tmp = x[idx]\n",
    "\n",
    "        # for f(x + h)\n",
    "        x[idx] = tmp + h\n",
    "        fh1 = f(x)\n",
    "\n",
    "        # for f(x - h)\n",
    "        x[idx] = tmp - h\n",
    "        fh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fh1 - fh2)/(2*h)\n",
    "        # restore x[idx]\n",
    "        x[idx] = tmp\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_numerical_gradient(fun2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_numerical_gradient(fun2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works with mini-batch as well\n",
    "def numerical_gradient(f, x):\n",
    "    if x.ndim == 1:\n",
    "        return _numerical_gradient(f, x)\n",
    "    else:\n",
    "        grad = np.zeros_like(x)\n",
    "        for idx, x in enumerate(x):\n",
    "            grad[idx] = _numerical_gradient(f, x)\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is an np array \n",
    "# x1^2 + x2^2\n",
    "\n",
    "def fun2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=300):\n",
    "    x = init_x\n",
    "\n",
    "    for i in range(step_num):\n",
    "        grad = _numerical_gradient(f, x)\n",
    "        x -= lr*grad\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x = np.array([-3.0, 5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.80603344e+12, -9.68668503e+12])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(fun2, init_x, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleNet:\n",
    "    def __init__(self):\n",
    "        self.w = np.random.randn(2, 3)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.w)\n",
    "\n",
    "\n",
    "    def softmax(self, a):\n",
    "        c = np.max(a)\n",
    "        a = np.exp(a - c)\n",
    "        s = np.sum(a)\n",
    "    \n",
    "        return a/s \n",
    "\n",
    "\n",
    "    def cross_entropy_error(self, y, t):\n",
    "        if y.ndim == 1:\n",
    "            t = t.reshape(1, t.size)\n",
    "            y = y.reshape(1, y.size)\n",
    "\n",
    "        batch_size = y.shape[0] \n",
    "        return -np.sum(t * np.log(y + 1e-7))/batch_size\n",
    "\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = self.softmax(z)\n",
    "        return self.cross_entropy_error(y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8870696 , -0.90016528, -1.70771816],\n",
       "       [-0.6574631 , -0.00693785,  1.39864672]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.59246593 -0.54495567 -0.0455782 ]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.7])\n",
    "t = np.array([1.0, 0.0, 0.0])\n",
    "\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1456233388286865"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52980256  0.20009953  0.32970303]\n",
      " [-0.61810298  0.23344945  0.38465353]]\n"
     ]
    }
   ],
   "source": [
    "def fun_test(w):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dw = numerical_gradient(fun_test, net.w)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1/(1 + np.exp(-a))\n",
    "\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    a = np.exp(a - c)\n",
    "    s = np.sum(a)\n",
    "\n",
    "    return a/s \n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    batch_size = y.shape[0] \n",
    "    return -np.sum(t * np.log(y + 1e-7))/batch_size\n",
    "\n",
    "def _numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "\n",
    "    grad = np.zeros_like(x) \n",
    "\n",
    "    for idx in range(x.size):\n",
    "        # save x[idx]\n",
    "        tmp = x[idx]\n",
    "\n",
    "        # for f(x + h)\n",
    "        x[idx] = tmp + h\n",
    "        fh1 = f(x)\n",
    "\n",
    "        # for f(x - h)\n",
    "        x[idx] = tmp - h\n",
    "        fh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fh1 - fh2)/(2*h)\n",
    "        # restore x[idx]\n",
    "        x[idx] = tmp\n",
    "\n",
    "    return grad\n",
    "\n",
    "# works with mini-batch as well\n",
    "def numerical_gradient(f, x):\n",
    "    if x.ndim == 1:\n",
    "        return _numerical_gradient(f, x)\n",
    "    else:\n",
    "        grad = np.zeros_like(x)\n",
    "        for idx, x in enumerate(x):\n",
    "            grad[idx] = _numerical_gradient(f, x)\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['w1'] = weight_init_std*np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['w2'] = weight_init_std*np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        w1, w2 = self.params['w1'], self.params['w2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "        a1 = np.dot(x, w1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "\n",
    "        a2 = np.dot(z1, w2) + b2\n",
    "        y = softmax(a2)\n",
    "\n",
    "        return y\n",
    "\n",
    "        \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "        grads = {}\n",
    "        grads['w1'] = numerical_gradient(loss_w, self.params['w1'])\n",
    "        grads['b1'] = numerical_gradient(loss_w, self.params['b1'])\n",
    "        grads['w2'] = numerical_gradient(loss_w, self.params['w2'])\n",
    "        grads['b2'] = numerical_gradient(loss_w, self.params['b2'])\n",
    "\n",
    "        return grads\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28 # 784\n",
    "net = TwoLayerNet(input_size=input_size, hidden_size=100, output_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "g = net.numerical_gradient(x, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w1': array([[ 7.87006371e-05,  1.40670764e-05, -1.33957379e-04, ...,\n",
       "          2.23477947e-04,  6.69482247e-05,  1.24709096e-04],\n",
       "        [ 7.65994557e-05,  1.39161820e-04, -1.34329454e-04, ...,\n",
       "          2.88309927e-04, -4.23102975e-05, -8.79665052e-05],\n",
       "        [ 1.83594331e-04,  5.86721427e-05, -7.14300796e-05, ...,\n",
       "          2.33155859e-04,  3.59331409e-05,  7.65318475e-06],\n",
       "        ...,\n",
       "        [ 2.40135520e-04, -3.78972587e-05, -1.47270320e-04, ...,\n",
       "          1.99010017e-04, -5.07480280e-05,  5.54969759e-05],\n",
       "        [-6.11241191e-05,  4.98168262e-05, -9.31372313e-05, ...,\n",
       "          3.68392676e-04,  1.55442663e-04,  4.98192776e-05],\n",
       "        [ 2.08788720e-04,  1.17665095e-04, -7.53012230e-05, ...,\n",
       "          2.19543317e-04, -3.64200403e-05, -7.26227967e-06]]),\n",
       " 'b1': array([ 1.92577403e-04,  1.09733627e-04, -2.31871802e-04,  1.29617952e-04,\n",
       "        -1.96194243e-04, -2.73089960e-04, -1.58896789e-04,  2.13109104e-04,\n",
       "        -9.05755115e-05,  2.63242406e-04,  1.86355464e-04, -2.27978241e-04,\n",
       "        -1.62165747e-05, -3.28072858e-05, -1.22229089e-04, -1.00306927e-04,\n",
       "        -1.01039141e-04, -1.37067815e-04, -3.61558463e-04, -2.80160606e-05,\n",
       "         3.25736984e-04,  2.11852829e-04, -1.94096472e-04,  2.50229348e-05,\n",
       "        -1.55013069e-04, -5.31676392e-05, -2.65294879e-04,  4.67431320e-04,\n",
       "        -2.36459989e-04,  2.39797018e-04,  1.27529525e-04, -1.86252187e-04,\n",
       "         1.16268950e-05,  5.44040688e-04, -1.53994613e-04, -1.32891920e-04,\n",
       "         1.12629621e-04, -2.10237729e-04, -6.95628799e-05,  3.42957520e-04,\n",
       "         4.03516900e-04,  2.12882405e-04,  7.09598780e-05, -1.19050334e-04,\n",
       "        -1.17668790e-04,  7.62184982e-06,  4.02715621e-04,  1.85529068e-04,\n",
       "         2.00455048e-04,  1.65967009e-04,  1.32837741e-05, -5.20374961e-04,\n",
       "         1.35763543e-04,  5.58189583e-04,  8.80521256e-05,  1.76426944e-04,\n",
       "        -3.50543417e-05,  3.37589157e-05, -1.02459587e-04,  3.19386650e-04,\n",
       "        -1.21610704e-04, -1.50245434e-04, -1.71868741e-04, -2.90464541e-05,\n",
       "         5.29084332e-06, -4.81950799e-04, -2.44158862e-04,  4.05085032e-05,\n",
       "        -3.15732507e-05,  2.23111840e-04,  1.60048543e-04, -1.42029464e-04,\n",
       "         3.59901122e-04,  3.15760218e-04,  2.78027379e-04,  3.25690444e-04,\n",
       "         1.86523934e-04,  4.45718875e-04, -1.48388182e-04,  1.84977473e-04,\n",
       "         8.32396516e-04,  3.46274298e-04, -1.82840907e-04, -3.78182392e-04,\n",
       "         5.04670901e-04,  3.33230510e-04, -4.21766124e-04, -1.33579086e-04,\n",
       "        -1.35530485e-04,  2.55766075e-04,  3.42897017e-04, -2.21480043e-04,\n",
       "         2.07734239e-04, -2.55109356e-04, -4.00716544e-04,  4.70583501e-04,\n",
       "        -2.10626538e-05,  5.14157712e-04,  6.90282320e-05,  2.48443044e-05]),\n",
       " 'w2': array([[-0.01076882,  0.02325483,  0.03361046, -0.02756466, -0.00318835,\n",
       "         -0.00436903, -0.0277116 ,  0.00659312,  0.00173742,  0.00808154],\n",
       "        [-0.01069249,  0.0220633 ,  0.03418167, -0.02648219, -0.00408709,\n",
       "         -0.00461181, -0.0285728 ,  0.00650017,  0.00148586,  0.00737918],\n",
       "        [-0.01070704,  0.02005426,  0.03013327, -0.02445705, -0.00272074,\n",
       "         -0.00421577, -0.02546914,  0.00623552,  0.00308146,  0.00747962],\n",
       "        [-0.01149624,  0.02382862,  0.03432964, -0.02755536, -0.00415409,\n",
       "         -0.00509192, -0.02771246,  0.0076565 ,  0.00291759,  0.00799143],\n",
       "        [-0.01113165,  0.02189086,  0.03316225, -0.02620769, -0.00461576,\n",
       "         -0.00517714, -0.02835517,  0.00744539,  0.00279728,  0.00868094],\n",
       "        [-0.01135444,  0.02326236,  0.03479532, -0.02711177, -0.00297538,\n",
       "         -0.00526131, -0.02804215,  0.00844436,  0.00141891,  0.00816474],\n",
       "        [-0.01199618,  0.02359269,  0.03521324, -0.02905094, -0.00343153,\n",
       "         -0.00602244, -0.02821706,  0.0069249 ,  0.00140161,  0.00951283],\n",
       "        [-0.01058322,  0.02068353,  0.0324426 , -0.02631692, -0.0036051 ,\n",
       "         -0.00412192, -0.02730847,  0.00731928,  0.00238337,  0.00688207],\n",
       "        [-0.01036672,  0.02175342,  0.03415845, -0.0263326 , -0.0029161 ,\n",
       "         -0.00448614, -0.02767908,  0.00702222,  0.00274591,  0.00821912],\n",
       "        [-0.00960784,  0.02113575,  0.03429766, -0.0262627 , -0.00345354,\n",
       "         -0.00553256, -0.02799765,  0.0061232 ,  0.0017457 ,  0.00863432],\n",
       "        [-0.01025008,  0.02205939,  0.0329194 , -0.0260745 , -0.00283262,\n",
       "         -0.00565144, -0.02692984,  0.00623525,  0.0016521 ,  0.00754306],\n",
       "        [-0.01002566,  0.02111677,  0.03169283, -0.02392375, -0.00316114,\n",
       "         -0.0057268 , -0.02616728,  0.00669333,  0.00149883,  0.00670775],\n",
       "        [-0.01017649,  0.02075303,  0.03263892, -0.02526612, -0.00338979,\n",
       "         -0.00544378, -0.02754972,  0.00641273,  0.00086883,  0.00680935],\n",
       "        [-0.00980617,  0.02079507,  0.03296502, -0.02596472, -0.00367285,\n",
       "         -0.00424731, -0.02784628,  0.00715257,  0.00228368,  0.00828332],\n",
       "        [-0.01130977,  0.02048226,  0.03265164, -0.02608973, -0.00399647,\n",
       "         -0.00456417, -0.0267739 ,  0.00762197,  0.00143913,  0.00777173],\n",
       "        [-0.00958644,  0.02014443,  0.0318688 , -0.02499837, -0.00236959,\n",
       "         -0.00540389, -0.02632891,  0.00712648,  0.00304896,  0.00709511],\n",
       "        [-0.01048732,  0.02036879,  0.03269353, -0.02534008, -0.00362097,\n",
       "         -0.0045357 , -0.02578792,  0.00715872,  0.00117375,  0.00742905],\n",
       "        [-0.01049058,  0.02077438,  0.03057262, -0.0249565 , -0.00371705,\n",
       "         -0.0040651 , -0.02561898,  0.00757054,  0.00201185,  0.00820602],\n",
       "        [-0.01063852,  0.0236492 ,  0.03431181, -0.02677034, -0.00222506,\n",
       "         -0.0054428 , -0.02934426,  0.00657361,  0.00185113,  0.00802258],\n",
       "        [-0.01050105,  0.02377172,  0.03486717, -0.02701463, -0.00277999,\n",
       "         -0.00572076, -0.02771077,  0.00727845,  0.00070476,  0.00903999],\n",
       "        [-0.01023613,  0.01990755,  0.03057952, -0.02444909, -0.00299167,\n",
       "         -0.00509992, -0.02542018,  0.00633148,  0.00215487,  0.00694373],\n",
       "        [-0.00996313,  0.02151896,  0.03136716, -0.02512247, -0.00329186,\n",
       "         -0.00532999, -0.02495007,  0.00668947,  0.00123516,  0.00765699],\n",
       "        [-0.01033493,  0.02277171,  0.03279489, -0.02743479, -0.00328738,\n",
       "         -0.00533336, -0.02800697,  0.00649333,  0.00057592,  0.00795794],\n",
       "        [-0.00977324,  0.02151137,  0.03226309, -0.02429036, -0.00451884,\n",
       "         -0.00560329, -0.02645097,  0.00754002,  0.00153423,  0.00834039],\n",
       "        [-0.01164812,  0.02270685,  0.03409451, -0.02746756, -0.00440137,\n",
       "         -0.00617767, -0.02732133,  0.00767171,  0.00198803,  0.0076959 ],\n",
       "        [-0.01023848,  0.02109892,  0.03114848, -0.02495255, -0.00397499,\n",
       "         -0.00458088, -0.02602966,  0.00592137,  0.00188374,  0.00755357],\n",
       "        [-0.0102209 ,  0.0214072 ,  0.03081242, -0.02393162, -0.00298523,\n",
       "         -0.00383354, -0.02584669,  0.00634103,  0.00197292,  0.00752169],\n",
       "        [-0.00870562,  0.01861607,  0.02630991, -0.02219476, -0.0024764 ,\n",
       "         -0.00390727, -0.02297335,  0.00525228,  0.00113608,  0.00659889],\n",
       "        [-0.00920182,  0.01985388,  0.02988076, -0.02343497, -0.00370197,\n",
       "         -0.00320849, -0.02445291,  0.00612363,  0.00218126,  0.00690959],\n",
       "        [-0.01238979,  0.02323162,  0.03555811, -0.02858574, -0.00391915,\n",
       "         -0.00632092, -0.02974401,  0.00762999,  0.00243123,  0.00841948],\n",
       "        [-0.00995632,  0.0208953 ,  0.03071349, -0.02493742, -0.00231792,\n",
       "         -0.00546377, -0.02666844,  0.00594792,  0.00302728,  0.00716223],\n",
       "        [-0.01121853,  0.02237518,  0.03389827, -0.02702529, -0.00291298,\n",
       "         -0.00414438, -0.02751732,  0.00757852,  0.00249963,  0.0080483 ],\n",
       "        [-0.0106809 ,  0.02159211,  0.03320158, -0.02629911, -0.00265224,\n",
       "         -0.0040922 , -0.02511676,  0.0061841 ,  0.00229541,  0.0077125 ],\n",
       "        [-0.01185354,  0.02359568,  0.0367755 , -0.02829408, -0.00295265,\n",
       "         -0.00595679, -0.02985179,  0.00826904,  0.00261118,  0.00894682],\n",
       "        [-0.00783146,  0.01765541,  0.02858348, -0.02138583, -0.00312263,\n",
       "         -0.00477228, -0.02203696,  0.00559546,  0.00079793,  0.00677599],\n",
       "        [-0.0103021 ,  0.0220288 ,  0.03268658, -0.02543573, -0.00376061,\n",
       "         -0.00530496, -0.02784605,  0.00734974,  0.00234692,  0.00706934],\n",
       "        [-0.01106396,  0.02423436,  0.03449523, -0.02767226, -0.00341238,\n",
       "         -0.00587572, -0.02799009,  0.00733687,  0.00225553,  0.00914124],\n",
       "        [-0.01131248,  0.02351621,  0.03732349, -0.02821831, -0.00335236,\n",
       "         -0.00553369, -0.0304781 ,  0.00838639,  0.00209207,  0.00861657],\n",
       "        [-0.01130655,  0.02387186,  0.03559499, -0.02741966, -0.00217402,\n",
       "         -0.00547033, -0.02969838,  0.00688291,  0.00256677,  0.00885317],\n",
       "        [-0.0103565 ,  0.02308265,  0.0350535 , -0.0287301 , -0.00337493,\n",
       "         -0.00617642, -0.02742082,  0.0065077 ,  0.0010909 ,  0.00843084],\n",
       "        [-0.01220746,  0.02515277,  0.03767759, -0.02940754, -0.00362454,\n",
       "         -0.00677111, -0.03117005,  0.00831451,  0.00185477,  0.00916983],\n",
       "        [-0.00940491,  0.01937828,  0.0291809 , -0.02250072, -0.00428618,\n",
       "         -0.00474329, -0.02472332,  0.00648262,  0.00145026,  0.00627774],\n",
       "        [-0.01088129,  0.02262633,  0.03393612, -0.0270877 , -0.00324323,\n",
       "         -0.00415862, -0.02747309,  0.00674869,  0.00109073,  0.00788562],\n",
       "        [-0.01022071,  0.0220195 ,  0.03087121, -0.02591818, -0.00350228,\n",
       "         -0.00409415, -0.02557319,  0.00687344,  0.00202607,  0.00807702],\n",
       "        [-0.00993805,  0.01885927,  0.02906121, -0.02308331, -0.00302885,\n",
       "         -0.00378323, -0.02398009,  0.00636533,  0.00167203,  0.00783865],\n",
       "        [-0.01182518,  0.02461951,  0.03587279, -0.02861866, -0.00367406,\n",
       "         -0.00526423, -0.02940026,  0.00725995,  0.00211977,  0.00887215],\n",
       "        [-0.00987473,  0.01977418,  0.02899716, -0.02398316, -0.00257892,\n",
       "         -0.00439161, -0.02448449,  0.00551404,  0.00168579,  0.00781796],\n",
       "        [-0.01126191,  0.02422603,  0.03361219, -0.02588735, -0.00304115,\n",
       "         -0.00483834, -0.0276016 ,  0.00732092,  0.00296413,  0.00898556],\n",
       "        [-0.01121147,  0.02310952,  0.03397637, -0.02766659, -0.00288479,\n",
       "         -0.0050661 , -0.02900466,  0.00672534,  0.00175719,  0.00794591],\n",
       "        [-0.0098787 ,  0.02052182,  0.03243074, -0.02477803, -0.00411052,\n",
       "         -0.00468592, -0.02504776,  0.00620572,  0.00193685,  0.00758661],\n",
       "        [-0.00964279,  0.02145069,  0.03218224, -0.02565359, -0.00359531,\n",
       "         -0.00571311, -0.02744183,  0.00579487,  0.00115073,  0.00802617],\n",
       "        [-0.01031536,  0.02009273,  0.03041581, -0.02435115, -0.00234985,\n",
       "         -0.00370703, -0.02447878,  0.00732867,  0.00181993,  0.00733439],\n",
       "        [-0.01266466,  0.02405193,  0.03759773, -0.03006347, -0.00406412,\n",
       "         -0.00591735, -0.03085412,  0.00801454,  0.00245008,  0.00919768],\n",
       "        [-0.01079029,  0.02204605,  0.0310548 , -0.02611854, -0.00319112,\n",
       "         -0.00499119, -0.02697612,  0.00668609,  0.00186385,  0.00700411],\n",
       "        [-0.01259822,  0.0245048 ,  0.03636446, -0.02917674, -0.00358841,\n",
       "         -0.00576945, -0.03066568,  0.00800493,  0.00304398,  0.00903229],\n",
       "        [-0.01093345,  0.02141797,  0.03030749, -0.02563602, -0.00330387,\n",
       "         -0.00529912, -0.02448852,  0.00684628,  0.00343429,  0.00738413],\n",
       "        [-0.01234229,  0.02480579,  0.03673073, -0.03001142, -0.00381702,\n",
       "         -0.00578738, -0.03121613,  0.00793618,  0.00159624,  0.00858555],\n",
       "        [-0.00988959,  0.01972641,  0.03127392, -0.02470718, -0.00317485,\n",
       "         -0.00419938, -0.02528777,  0.00671612,  0.00176055,  0.00707116],\n",
       "        [-0.01125224,  0.02123289,  0.03492145, -0.02650009, -0.00311002,\n",
       "         -0.00548047, -0.02928777,  0.00835121,  0.00269856,  0.0080381 ],\n",
       "        [-0.01133446,  0.0238658 ,  0.03525471, -0.02770539, -0.00406414,\n",
       "         -0.0057367 , -0.02882469,  0.00794648,  0.00176301,  0.00871636],\n",
       "        [-0.00983933,  0.02062664,  0.03166824, -0.0247221 , -0.00375669,\n",
       "         -0.00385907, -0.02610929,  0.00659172,  0.00182088,  0.00734898],\n",
       "        [-0.01181759,  0.02286836,  0.03441028, -0.02803777, -0.00280823,\n",
       "         -0.0053148 , -0.02932523,  0.00700999,  0.00216678,  0.00870402],\n",
       "        [-0.00959065,  0.01986164,  0.03144726, -0.02489227, -0.00320472,\n",
       "         -0.00506391, -0.02598401,  0.00666235,  0.00120822,  0.00748942],\n",
       "        [-0.0102174 ,  0.02218011,  0.03333828, -0.0272497 , -0.00328203,\n",
       "         -0.00465449, -0.02688102,  0.00674602,  0.00295946,  0.00827215],\n",
       "        [-0.00965121,  0.0196425 ,  0.02880835, -0.02407715, -0.00281127,\n",
       "         -0.00458094, -0.02504887,  0.00579561,  0.00252118,  0.00727392],\n",
       "        [-0.00933436,  0.02088288,  0.03250422, -0.02513865, -0.00298193,\n",
       "         -0.00412737, -0.02642124,  0.00646323,  0.00159736,  0.00684433],\n",
       "        [-0.00939677,  0.02105744,  0.03180016, -0.02488665, -0.00343007,\n",
       "         -0.0048845 , -0.0268111 ,  0.00707097,  0.0026465 ,  0.00819741],\n",
       "        [-0.00945066,  0.01995333,  0.02951879, -0.02286172, -0.00313218,\n",
       "         -0.00527462, -0.02415861,  0.00609959,  0.00100637,  0.00688888],\n",
       "        [-0.01068523,  0.02310054,  0.03450727, -0.02659419, -0.00353821,\n",
       "         -0.00564946, -0.02849803,  0.00755673,  0.00324283,  0.00820534],\n",
       "        [-0.01071837,  0.02147898,  0.03378934, -0.0262532 , -0.00387572,\n",
       "         -0.00416652, -0.02665063,  0.00656914,  0.00229364,  0.00801464],\n",
       "        [-0.01019452,  0.02177955,  0.03269148, -0.02602304, -0.00283401,\n",
       "         -0.00377373, -0.02646948,  0.00703588,  0.00235658,  0.00909926],\n",
       "        [-0.01052131,  0.02232626,  0.03532109, -0.02645785, -0.00409905,\n",
       "         -0.00542768, -0.02821812,  0.00675945,  0.00201105,  0.00906334],\n",
       "        [-0.00965576,  0.02252902,  0.03371189, -0.02726863, -0.00293761,\n",
       "         -0.00445939, -0.0276118 ,  0.00713378,  0.00116937,  0.00729314],\n",
       "        [-0.01132264,  0.02285982,  0.03592955, -0.0280112 , -0.00363761,\n",
       "         -0.00635854, -0.02842922,  0.00818949,  0.00186345,  0.0080001 ],\n",
       "        [-0.00888736,  0.01768081,  0.02733968, -0.02133779, -0.00271079,\n",
       "         -0.00387043, -0.02282931,  0.00629522,  0.00086613,  0.00611734],\n",
       "        [-0.01153095,  0.02386934,  0.03485037, -0.02734071, -0.00390188,\n",
       "         -0.00449735, -0.02852992,  0.00762259,  0.00212048,  0.00841659],\n",
       "        [-0.01091912,  0.02282542,  0.03153221, -0.02638341, -0.00324223,\n",
       "         -0.00459091, -0.02649338,  0.00623853,  0.00298159,  0.00805732],\n",
       "        [-0.00827997,  0.01847787,  0.02832198, -0.02232569, -0.00193997,\n",
       "         -0.00497716, -0.02353755,  0.00601785,  0.00189793,  0.00624629],\n",
       "        [-0.01012087,  0.02201626,  0.03358912, -0.02433395, -0.00265145,\n",
       "         -0.00559616, -0.02724977,  0.0075647 ,  0.00223287,  0.00757004],\n",
       "        [-0.01011704,  0.02119961,  0.0314915 , -0.0248755 , -0.00347212,\n",
       "         -0.00404866, -0.02684416,  0.00600726,  0.00220562,  0.00871968],\n",
       "        [-0.01088716,  0.02133859,  0.03338666, -0.02594354, -0.00322494,\n",
       "         -0.0041064 , -0.02653674,  0.00710911,  0.00221881,  0.00706385],\n",
       "        [-0.00993611,  0.0231201 ,  0.03426152, -0.0271282 , -0.00358069,\n",
       "         -0.00475185, -0.02883696,  0.00761112,  0.00145389,  0.00886326],\n",
       "        [-0.00975813,  0.02086744,  0.03106456, -0.02471764, -0.00318308,\n",
       "         -0.00501408, -0.02613418,  0.00723943,  0.00221138,  0.00794454],\n",
       "        [-0.00979489,  0.02063682,  0.03169017, -0.02505007, -0.0031439 ,\n",
       "         -0.00500624, -0.0257293 ,  0.00601485,  0.00133633,  0.0079013 ],\n",
       "        [-0.01094493,  0.02141582,  0.03061731, -0.0264158 , -0.00383966,\n",
       "         -0.00421726, -0.0267491 ,  0.00622294,  0.00252463,  0.00829751],\n",
       "        [-0.00971056,  0.0203626 ,  0.03132384, -0.02429627, -0.00209882,\n",
       "         -0.00357244, -0.02528976,  0.00616951,  0.00122088,  0.00825385],\n",
       "        [-0.01116079,  0.02172296,  0.03442292, -0.02704742, -0.0031315 ,\n",
       "         -0.00468286, -0.02883493,  0.00693957,  0.00258339,  0.00760834],\n",
       "        [-0.0118226 ,  0.02326497,  0.03493482, -0.02804205, -0.00441858,\n",
       "         -0.00496849, -0.02798195,  0.00710753,  0.00188646,  0.00803133],\n",
       "        [-0.01166676,  0.02306369,  0.03530921, -0.02720934, -0.00307782,\n",
       "         -0.00484405, -0.02769867,  0.00746349,  0.0018458 ,  0.00807749],\n",
       "        [-0.01203999,  0.02405512,  0.0363775 , -0.0286231 , -0.00361845,\n",
       "         -0.00493605, -0.02869289,  0.00854343,  0.00280245,  0.00988267],\n",
       "        [-0.01051867,  0.02026751,  0.03133121, -0.02473177, -0.00279232,\n",
       "         -0.0049149 , -0.02586315,  0.00637017,  0.00269332,  0.00843198],\n",
       "        [-0.01072473,  0.02205484,  0.03275968, -0.02582757, -0.00350899,\n",
       "         -0.00506192, -0.02755266,  0.00649642,  0.00147465,  0.00818161],\n",
       "        [-0.01058603,  0.02217192,  0.03594872, -0.02652924, -0.00401428,\n",
       "         -0.00578789, -0.02745579,  0.00771161,  0.00176963,  0.00807082],\n",
       "        [-0.00995216,  0.0207812 ,  0.03103684, -0.02605091, -0.00243045,\n",
       "         -0.00470132, -0.02599494,  0.00591598,  0.00178094,  0.00798765],\n",
       "        [-0.00970677,  0.02314396,  0.03431573, -0.02545223, -0.00305397,\n",
       "         -0.00571883, -0.02695275,  0.00829079,  0.00272265,  0.00791155],\n",
       "        [-0.00868423,  0.01803634,  0.02883397, -0.02185451, -0.00289034,\n",
       "         -0.00369868, -0.02209677,  0.00612951,  0.00242887,  0.00744368],\n",
       "        [-0.01098655,  0.02358138,  0.0356502 , -0.02858312, -0.00370716,\n",
       "         -0.00576352, -0.03003808,  0.00802564,  0.00141187,  0.00853875],\n",
       "        [-0.01129947,  0.02204942,  0.03399138, -0.02676858, -0.00281961,\n",
       "         -0.00545999, -0.02730583,  0.00712667,  0.00212358,  0.0082893 ],\n",
       "        [-0.01065047,  0.02256267,  0.03428937, -0.02738059, -0.00256963,\n",
       "         -0.00432056, -0.02839392,  0.00755027,  0.0023342 ,  0.00859049],\n",
       "        [-0.01128135,  0.02332864,  0.03548129, -0.02780469, -0.00289637,\n",
       "         -0.00490218, -0.029798  ,  0.00671985,  0.00245271,  0.00873843]]),\n",
       " 'b2': array([-0.02101926,  0.04361402,  0.0659187 , -0.05183167, -0.00668357,\n",
       "        -0.00973198, -0.05406841,  0.01382768,  0.0039931 ,  0.01598138])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_data import MnistData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with loading images:  train-images-idx3-ubyte.gz\n",
      "Done with loading labels:  train-labels-idx1-ubyte.gz\n",
      "Done with loading images:  t10k-images-idx3-ubyte.gz\n",
      "Done with loading labels:  t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_data = MnistData()\n",
    "(x_train, t_train), (x_test, t_test) = mnist_data.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70 86  0 21 71]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.04451108, 0.07528287, 0.54161293, 0.91528426, 0.41196233])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = np.random.rand(100)\n",
    "batch_mask = np.random.choice(100, 5)\n",
    "print(batch_mask)\n",
    "x_t[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04451107856045655"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "iters_num = 10000 \n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "input_size = 28*28 # 784\n",
    "net = TwoLayerNet(input_size=input_size, hidden_size=100, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # mini-batch\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = net.numerical_gradient(x_batch, t_batch)\n",
    "    for key in ('w1', 'b1', 'w2', 'b2'):\n",
    "        net.params[key] -= learning_rate*grad[key]\n",
    "\n",
    "loss = net.loss(x_batch, t_batch)\n",
    "train_loss.append(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
